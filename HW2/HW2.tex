\documentclass[11pt]{article}

\usepackage{amsfonts}

\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsrefs}
\usepackage{ulem}
\usepackage[dvips]{graphicx}
\usepackage{color}
\usepackage{bm}
\usepackage{cancel}

\setlength{\headheight}{26pt}
\setlength{\oddsidemargin}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.5in}

\topmargin 0pt
%Forrest Shortcuts
\newtheorem{defn}{Definition}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{pf}{Proof}
\newtheorem{sol}{Solution}
\newcommand{\R}{{\ensuremath{\mathbb R}}}
\newcommand{\J}{{\ensuremath{\mathbb J}}}
\newcommand{\Z}{{\mathbb Z}}
\newcommand{\N}{{\mathbb N}}
\newcommand{\T}{{\mathbb T}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\st}{{\text{\ s.t.\ }}}
\newcommand{\rto}{\hookrightarrow}
\newcommand{\rtto}{\hookrightarrow\rightarrow}
\newcommand{\tto}{\to\to}
\newcommand{\C}{{\mathbb C}}
\newcommand{\ep}{\epsilon}
%CJ shortcuts
\newcommand{\thin}{\thinspace}
\newcommand{\beps}{\boldsymbol{\epsilon}}
\newcommand{\bwoc}{by way of contradiction}

%Munkres formatting?
%\renewcommand{\theenumii}{\alph{enumi}}
\renewcommand{\labelenumi}{\theenumi.}
\renewcommand{\theenumii}{\alph{enumii}}
\renewcommand{\labelenumii}{(\theenumii)}

\title{HW2}
\author{Guanlin Zhang}

\lhead{Dr Milind Phadnis
 \\BIOS 845} \chead{}
\rhead{Guanlin Zhang\\ Spring '18} \pagestyle{fancyplain}
%\maketitle

\begin{document}

Question $\# 1$:
\begin{sol}
	Exercise $7.4$:\vskip 2mm
	We run log-rank test for part $(a)$ and wilcoxon test for part $(b)$ since in part $(b)$ we are giving more weight to earlier part of the survival.\vskip 2mm
	We have the following SAS code:
	\begin{center}
		\includegraphics[width = 12cm]{ex7_4_1.jpg}
	\end{center}
	with output:
	\begin{center}
		\includegraphics[width = 12cm]{ex7_4_2.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 6cm]{ex7_4_3.jpg}
	\end{center}
	However both the log-rank test and wilcoxon test results are not significant given significance level $\alpha = 0.05$(p value $0.09$ for log-rank and $0.07$ for wilcoxon).\vskip 2mm
	So we conclude that there is not enough evidence showing that the survival rates of patients with cancer of tongue are different for patients with aneuploid and diploid tumors, using both log-rank test and wilcoxon test.\vskip 2mm
	Exercise $7.12$:\vskip 2mm
	We input the data and run the Renyi statistic as the class example:
	\begin{center}
		\includegraphics[width = 12cm]{ex7_12_1.jpg}
	\end{center}
	For part $(a)$ we have the following output:
	\begin{center}
		\includegraphics[width = 10cm]{ex7_12_2.jpg}
	\end{center}
	we report the p value as not significant given the level $\alpha = 0.05$, but it is really close. We can conclude that we fail to reject the null hypothesis and think there is no enough evidence showing a significant difference of hazard rate, but addressing that p value is close to the significance level.
	and for part $(b)$ we have:
	\begin{center}
		\includegraphics[width = 10cm]{ex7_12_3.jpg}
	\end{center}
	The p value is insignificant and we fail to reject the null hypothesis. So we conclude that there is not enough evidence supporting that there is a different hazard rate between the two groups of patients.
\end{sol}

Question $\#2$:
\begin{sol}
	We use log-rank test for part $(a)$ and Fleming test with $p <q$ for part $(b)$. Because we are more interested in long term efficacy of the treatment and fleming test with $p <q$ put more weights on later event time. After a few trial we particularly choose $p = 0$ and $q = 0.5$. The code is:
	\begin{center}
		\includegraphics[width = 10cm]{Q201.jpg}
	\end{center}
	and the output is:
	\begin{center}
		\includegraphics[width = 6cm]{Q202.jpg}
	\end{center}
	For logrank test the p value is not significant. We fail to reject the null hypothesis and conclude that there is not enough evidence showing that the AZT + ddC + saquinvavir is more effective (provides longer survival,or smaller hazard rate) than the AZT + ddc treatment.\vskip 2mm
	For Flemming test with the $p = 0$ and $q = 0.5$, the p value is marginally significant ($p = 0.06$) which shows stronger evidence than the logrank test that AZT+ddc+saquinvair is more effective in the long term.\vskip 2mm
	For part $(c)$ and part $(d)$ we fit separately an exponential AFT and weibull AFT model with a single dichotomous covariate representing treatment group. We have the following code:
	\begin{center}
		\includegraphics[width = 10cm]{Q203.jpg}
	\end{center}
	For the exponential model, our output is:
	\begin{center}
		\includegraphics[width = 14cm]{Q204.jpg}
	\end{center}
	with AZT + ddc + saquinivir as the reference group, the regression coefficient for AZT + ddc is $-0.5001$(this makes sense since we expect the triple drug combinations to enhance survival). But the p value is $0.19$ and not significant, which means we fail to reject the null hypothesis and conclude that there is not enough evidence showing different effectiveness between groups. Also, the p value for testing $H_0: \sigma = 1$ is $0.72$ and highly insignificant, so we fail to reject that $H_0: \sigma= 1$, and this support model assumption for exponential model.\vskip 2mm
	For the Weibull model, our output is:
	\begin{center}
		\includegraphics[width = 14cm]{Q205.jpg}
	\end{center}
	The regression coefficient is $-0.5008$ with p value $0.17$. It is not significant and we conclude that there is not enough evidence supporting the different effectiveness between treatment group and we faill to reject the null hypothesis that different treatment groups have the same hazard rate.\vskip 2mm
	The estimate for scale is $0.9459$ indicating that the hazard rate increases at a decreasing rate.However it is pretty close to $1$, and also the $95\%$ confidence interval includes $1$ still, so we may for now keep the exponential model as a candidate.\vskip 2mm
	 For part $(e)$, to perform a likelihood ratio test, notice that exponential model is nested in the weibull model, and the difference of the degree of freedom is:
	 \begin{align*}
	 	df_w - df_e = 2 - 1 = 1
	 \end{align*}
	 From the code we gave above for $(c)$ and $(d)$, we can separately get :
	 \begin{align*}
	 	LL_e &= -49.213007\\
	 	LL_w &= -49.1545919\\ 
	 \end{align*}
	 So we have:
	 \begin{align*}
	 	-2(LL_e - LL_w) = 98.426 - 98.309 = 0.117
	 \end{align*}
	 So we can compute the p value with the following code:
	 \begin{align*}
	 	\text{pvalue} = 1 - probchi(0.117, 1) = 0.73
	 \end{align*}
	 a quick comment here, we can also use the unlogged response from the model to compute the fit statistics ($-2$ Log Likelihood), which is in the output of SAS proc lifereg as well, and we will have the same p value.\vskip 2mm
	 As we can see that the p value is highly insignificant, hence we fail to reject the null hypothesis and conclude that the exponential model fit just as well as the weibull.\vskip 2mm
	 We may also need to check if these two models are adequate compared to a more general model, which is the generalized gamma model. In the following code, we fit the generalized gamma model and run a likelihood formal test for both exponential and weibull models compared to gamma:
	 \begin{center}
		\includegraphics[width = 10cm]{Q206.jpg}
	\end{center}
	The p value for the $\chi^2$ tests are:
	\begin{center}
		\includegraphics[width = 4cm]{Q207.jpg}
	\end{center}
	Both as insignificant, so we conclude that the weibull and exponential models are adequate compared to generalized gamma.\vskip 2mm
	 For part $(f)$:\vskip 2mm
	 We sketch the negative log survival versus time and log-log survival versus log time with the following code and output:
	   \begin{center}
		\includegraphics[width = 12cm]{Q208.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 10cm]{Q209.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 10cm]{Q210.jpg}
	\end{center}
	The (LS) plot apparently does not line up as a straightline, which indicates that the exponential model is not adequate. This is not consistent with the conclusion from part $(e)$. This might be due to the small sample size from the data.\vskip 2mm
	The (LLS) plot gives a sort-of straightline, but still not very perfect. We would reserve our opinion and consider weibull distribution as candidate also for now for our final model.\vskip 2mm
	For part $(g)$:\vskip 2mm
	We fit the lognormal and log-logistic model with the following SAS code:
	\begin{center}
		\includegraphics[width = 12cm]{Q211.jpg}
	\end{center}
	The output for log-normal model is:
	\begin{center}
		\includegraphics[width = 4cm]{Q212.jpg}\includegraphics[width = 10cm]{Q213.jpg}
	\end{center}
	The log-likelihood value is $-52.20433928$.\vskip 2mm
	The chi-square test for the group effectiveness has a p value of $0.82$ which is highly insignificant, and we fail to reject the null and conclude that there is not enough evidence showing that there is a difference of effectiveness between groups.\vskip 2mm
	The output for log-logistic model is:
	\begin{center}
		\includegraphics[width = 4cm]{Q214.jpg}\includegraphics[width = 10cm]{Q215.jpg}
	\end{center}
	The log-likelihood value is $-51.82056127$.\vskip 2mm
	The chi-square test for the group effectiveness has a p value of $0.46$ which is insignificant, and we fail to reject the null and conclude that there is not enough evidence showing that there is a difference of effectiveness between groups.\vskip 2mm
	So far among all the models we have fit (exponential, weibull, log-normal and log-logistic), none of them is showing significance for the differenct effectivess between groups. So it seems that the effectiveness of treatment does not depend on the distributional assumptions.\vskip 2mm
	For part $(h)$:\vskip 2mm
	To compare between models that are not nested, we need to look at the AIC value. From the code above we have:
	\begin{align*}
		\text{AIC}_{exponential} &= 102.426\\
		\text{AIC}_{weibull} &= 104.309\\
		\text{AIC}_{lognormal} &= 110.409\\
		\text{AIC}_{loglogistic} &= 109.641
	\end{align*}
	The exponential model has the smallest AIC, and previously the formal test in part $(e)$ also says that exponential is adequate enough compared to weibull. Although the negative log survival is against this statement, but we pointed out that this might be due to the small sample size. From the output of weibull model we see that both the scale and shape parameters have an estimate close to $1$. Hence we consdier the exponential model as appropraite.\vskip 2mm
	Between exponential and weibull, although both can be used, we are in favor of exponential. First reason is that we have done likelihood ratio test and the formal test shows that exponential model is adequate compared to weibull. Secondly, exponential model has the smallest AIC value among all four models we have fun. Third reason is that whenever possible we prefer to choose the simpler model than the more complicated ones.\vskip 2mm
	For part $(i)$:\vskip 2mm
	The following code plots the survival curves for the two treatment under exponential model:
	\begin{center}
		\includegraphics[width = 8cm]{Q216.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 10cm]{Q217.jpg}
	\end{center}
\end{sol}

Question $\#3$.
\begin{sol}
	For part $(a)$:\vskip 2mm
	For (i) we have:
	\begin{align*}
		F_{X^{\gamma}}(x)= P(X^{\gamma} \leq x) = P(X \leq x^{\frac{1}{\gamma}})= F_X(x^{\frac{1}{\gamma}})
	\end{align*}
	So
	\begin{align*}
		f_{X^{\gamma}}(x) &= f_{X}(x^{\frac{1}{\gamma}})\cdot \frac{1}{\gamma}\cdot x^{\frac{1}{\gamma} - 1}\\
		&= \frac{\cancel{\gamma}}{\beta}\cdot \Big(x^{\frac{1}{\gamma}}\Big)^{\gamma - 1}\cdot \exp\Big(-(x^{\frac{1}{\gamma}})^{\gamma}/\beta\Big)\cdot \frac{1}{\cancel{\gamma}}\cdot x^{\frac{1}{\gamma} - 1}\\
		&= \frac{1}{\beta}\cdot x^{1 - \frac{1}{\gamma}}\cdot \exp\Big(-x/\beta\Big)\cdot x^{\frac{1}{\gamma} - 1}\\
		&= \frac{1}{\beta}\cdot \exp\Big(-\frac{x}{\beta}\Big) \sim \exp(\beta)
	\end{align*}
	For (ii) we have:
	\begin{align*}
		F_{cX} = P(c X \leq x) = P(X \leq \frac{x}{c}) = F_X(\frac{x}{c})
	\end{align*}
	So
	\begin{align*}
		f_{cX} &= f_X(\frac{x}{c})\cdot \frac{1}{c}\\
		&= \frac{\gamma}{\beta}\cdot \Big(\frac{x}{c}\Big)^{\gamma - 1}\cdot \exp\Big(-(\frac{x}{c})^{\gamma}/\beta\Big)\cdot \frac{1}{c}\\
		&= \frac{\gamma }{\beta  c^{\gamma}}\cdot x^{\gamma - 1}\exp\Big(-x^{\gamma}/(\beta c^{\gamma})\Big) \sim Weibull(\gamma, \beta c^{\gamma})
	\end{align*}
	For $(iii)$ we have:
	\begin{align*}
		F_{X^{\frac{1}{\gamma}}} &= P(X^{\frac{1}{\gamma}} \leq x) = P(X \leq x^{\gamma}) = F_X(x^{\gamma})
	\end{align*}
	So
	\begin{align*}
		f_{X^{\frac{1}{\gamma}}} &= f_X(x^{\gamma})\cdot \gamma \cdot x^{\gamma - 1}\\
		&= \frac{\gamma}{\beta}\cdot \Big(x^{\gamma}\Big)^{\gamma - 1}\cdot \exp\Big(-(x^{\gamma})^{\gamma}/\beta\Big)\cdot \gamma \cdot x{\gamma - 1}\\
		&= \frac{\gamma}{\beta}\cdot x^{\gamma(\gamma - 1)}\cdot \exp\Big(-x^{\gamma^2}/\beta\Big)\cdot \gamma \cdot x^{\gamma - 1}\\
		&= \frac{\gamma^2}{\beta}\cdot x^{\gamma^2 - 1}\cdot \exp\Big(-x^{\gamma^2}/\beta\Big) \sim Weibull(\gamma^2, \beta)
	\end{align*}
	For $(iv)$, \vskip 2mm
	Suppose the median of $X$ is denoted as $M$, then we have:
	\begin{align*}
		\frac{1}{2} &= S_X(M) = \exp\Big(-\frac{1}{\beta}\cdot M^{\gamma}\Big) \\
		&\Longrightarrow -\frac{1}{\beta}\cdot M^{\gamma} = \log\frac{1}{2}\\
		&\Longrightarrow M^{\gamma} = -\beta\log\frac{1}{2} = \beta\log 2\\
		&\Longrightarrow M = \beta^{\frac{1}{\gamma}}\cdot (\log 2)^{\frac{1}{\gamma}}
	\end{align*}
	The mode of a distribution is the value of $x$ at which the probability density function reaches maximum.\vskip 2mm
	We have:
	\begin{align*}
		f(x|\gamma, \beta) &= \frac{\gamma}{\beta}\cdot x^{\gamma - 1}\cdot \exp\Big(-x^{\gamma}/\beta\Big)
	\end{align*}
	If $\gamma >1$, we have:
	\begin{align*}
		\frac{d}{d x}f(x|\gamma, \beta) &= \frac{\gamma}{\beta}\cdot (\gamma - 1)\cdot x^{\gamma - 2}\cdot \exp\Big(-x^{\gamma}/\beta\Big) + \frac{\gamma}{\beta}\cdot x^{\gamma - 1}\cdot \exp\Big(-x^{\gamma}/\beta\Big)\cdot (-\frac{\gamma}{\beta})\cdot x^{\gamma - 1}\\
		&= \underbrace{\frac{\gamma}{\beta}\cdot x^{\gamma - 2}\cdot\exp\Big(-\frac{x^{\gamma}}{\beta}\Big)}_{(1)}\cdot  \underbrace{\Big[(\gamma - 1) - x^{\gamma}\cdot \frac{\gamma}{\beta}\Big]}_{(2)}
	\end{align*}
	apparently $(1) > 0$ regardless the value of $x$. If we set equation $\frac{d}{dx}f(x|\gamma, \beta) = 0$, we then have:
	\begin{align*}
		&\ (\gamma - 1) - x^{\gamma}\cdot \frac{\gamma}{\beta} = 0\\
		&\Longrightarrow x^{\gamma} = \frac{(\gamma - 1)\cdot \beta}{\gamma} = (1 - \frac{1}{\gamma})\beta\\
		&\Longrightarrow x = (1 - \frac{1}{\gamma})^{\frac{1}{\gamma}}\cdot \beta^{\frac{1}{\gamma}}
	\end{align*}
	and it is also easy to observe that when $x <(1 - \frac{1}{\gamma})^{\frac{1}{\gamma}}\cdot \beta^{\frac{1}{\gamma}} $, we have $\frac{d}{d x}f(x|\gamma, \beta) > 0$ and hence $f$ is increasing, and when $x > (1 - \frac{1}{\gamma})^{\frac{1}{\gamma}}\cdot \beta^{\frac{1}{\gamma}}$, we have $\frac{d}{d x}f(x|\gamma, \beta) < 0$ and hence $f$ is decreasing. So $f$ reaches maximum at 
	\begin{align*}
		x = (1 - \frac{1}{\gamma})^{\frac{1}{\gamma}}\cdot \beta^{\frac{1}{\gamma}}
	\end{align*}
	or we say, the mode when $\gamma >1$ is $x = (1 - \frac{1}{\gamma})^{\frac{1}{\gamma}}\cdot \beta^{\frac{1}{\gamma}}$.\vskip 2mm
	Now when $\gamma \leq 1$, we have the same expression for $\frac{d}{dx}f(x|\gamma, \beta) = (1) \times (2)$ but only this time $(2) < 0$ regardless the value of $x$. So $f$ is always decreasing and hence the maximum is approached when $x$ approaches $0$ from the right hand side, and hence $x = 0$ is the mode when $\lambda \leq 1$.\vskip 2mm
	For part $(b)$:\vskip 2mm
	Let $Y = \frac{x^{1/\beta}}{\theta}$ then we have:
	\begin{align*}
		F_Y(x) &= P(\frac{x^{1/\beta}}{\theta} \leq x) = P(X \leq (\theta x)^{\beta}) = F_X((\theta x)^{\beta})
	\end{align*}
	So
	\begin{align*}
		f_Y(x) &= f_X\Big((\theta x)^{\beta}\Big) \cdot \theta^{\beta}\cdot \beta \cdot x^{\beta - 1}\\
		&= \frac{\Big((\theta x)^{\beta}\Big)^{\alpha - 1}\cdot \exp\Big(-\frac{(\theta x)^{\beta}}{\beta}\Big)}{\Gamma(\alpha)\cdot \beta^{\alpha}}\cdot \theta^{\beta}\cdot \beta \cdot x^{\beta - 1}\\
		&= \frac{\theta^{\beta\alpha}\cdot \beta \cdot x^{\beta\alpha - 1}\cdot \exp\Big(-\frac{\theta^{\beta}\cdot x^{\beta}}{\beta}\Big)}{\Gamma(\alpha)\cdot \beta^{\alpha}}\\
		&= \frac{\beta\cdot x^{\alpha\beta - 1}\cdot \exp\Big[-\Big(\frac{x}{\beta^{1/\beta}/\theta}\Big)^{\beta}\Big]}{\Gamma(\alpha)\cdot \Big(\frac{\beta^{1/\beta}}{\theta}\Big)^{\beta\alpha}}
	\end{align*}
	So this is in the form of a generalized gamma distribution with shape parameter $\alpha, \beta$ and scale parameter $\frac{\beta^{1/\beta}}{\theta}$ as formatted in part 2 of lecture notes for chapter 5 on page 9.
\end{sol}

Question $\# 4$.
\begin{sol}
	The following SAS code input the data and run the logrank test on the matched pairs:
	\begin{center}
		\includegraphics[width = 14cm]{Q401.jpg}
	\end{center}
	The output is:
	\begin{center}
		\includegraphics[width = 6cm]{Q402.jpg}
	\end{center}
	The p value is $0.016$ which is significant, so we reject the null and conclude that there is a significant difference at level of $\alpha = 0.05$ between the exposed and controlled group on the time to tumor occurrence.
\end{sol}

Question $\#5$
\begin{sol}
	I confirm that I have read the paper and understand the derivation on page $\#246$.
\end{sol}


\end{document}
